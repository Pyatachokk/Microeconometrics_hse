#Подробней о ggplot2
#http://r-statistics.co/ggplot2-Tutorial-With-R.html
#https://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html
#-----------------------------------
#РАЗДЕЛ №11*. Использование C++ в R (для самых любопытных и продвинутых)
#-----------------------------------
#Загрузим и подключим необходимые библиотеки
install.packages("Rcpp")              #коннектор R к C++
install.packages("Rcpp11")            #чтобы использовать C++ 11 и старше
install.packages("RcppArmadillo")     #библиотека для быстрой работы с матрицами
library("Rcpp11")
library("RcppArmadillo")
library("Rcpp")
#Рассмотрим обычную линейную регрессию и бутстрапируем оценку ковариационной матрицы оценок
#Для начала симулируем данные
n <- 100000                        #количество наблюдений
x_1 <- rchisq(n,5)                 #симулируем n наблюдений первой независимой переменной
#из хи-квадрат распределения с 5 степенями свободы
x_2 <- runif(n,0,5)                #симулируем n наблюдений первой независимой переменной
#из равномерного распределения от 0 до 5
x_3 <- x_1 + x_2 + rt(n, 5)        #симулируем n наблюдений третьей независимой переменной
#как сумму первой, второй и случайной величины из t распределения
#с 5 степенями свободы
#из равномерного распределения от 0 до 5
sigma <- 3
epsilon <- rnorm(n, 0, sigma)      #симулируем n случайных ошибок из нормального распределения
#с математическим ожиданием 0 и дисперсией sigma
beta_0 <- 1                        #константа
beta_1 <- 2                        #коэффициент при первой независимой переменной
beta_2 <- 3                        #коэффициент при второй независимой переменной
beta_3 <- -1                       #коэффициент при третьей независимой переменной
y <- beta_0 +                      #создаем зависимую переменную
beta_1 * x_1 +
beta_2 * x_2 +
beta_3 * x_3 + epsilon
X <- cbind(1, x_1, x_2, x_3)       #создадим матрицу независимых переменных
